{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from datetime import datetime as dt\n",
    "\n",
    "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler,MinMaxScaler\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn import tree\n",
    "from sklearn import svm\n",
    "from sklearn import neighbors\n",
    "from sklearn import linear_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "historical_data = pd.read_csv('historical_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 197428 entries, 0 to 197427\n",
      "Data columns (total 16 columns):\n",
      " #   Column                                        Non-Null Count   Dtype  \n",
      "---  ------                                        --------------   -----  \n",
      " 0   market_id                                     196441 non-null  float64\n",
      " 1   created_at                                    197428 non-null  object \n",
      " 2   actual_delivery_time                          197421 non-null  object \n",
      " 3   store_id                                      197428 non-null  int64  \n",
      " 4   store_primary_category                        192668 non-null  object \n",
      " 5   order_protocol                                196433 non-null  float64\n",
      " 6   total_items                                   197428 non-null  int64  \n",
      " 7   subtotal                                      197428 non-null  int64  \n",
      " 8   num_distinct_items                            197428 non-null  int64  \n",
      " 9   min_item_price                                197428 non-null  int64  \n",
      " 10  max_item_price                                197428 non-null  int64  \n",
      " 11  total_onshift_dashers                         181166 non-null  float64\n",
      " 12  total_busy_dashers                            181166 non-null  float64\n",
      " 13  total_outstanding_orders                      181166 non-null  float64\n",
      " 14  estimated_order_place_duration                197428 non-null  int64  \n",
      " 15  estimated_store_to_consumer_driving_duration  196902 non-null  float64\n",
      "dtypes: float64(6), int64(7), object(3)\n",
      "memory usage: 24.1+ MB\n"
     ]
    }
   ],
   "source": [
    "historical_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "store_id  store_primary_category\n",
       "1         mexican                    8\n",
       "2         japanese                   5\n",
       "3         fast                       1\n",
       "          salad                      2\n",
       "4         asian                      1\n",
       "                                    ..\n",
       "6986      fast                      35\n",
       "          indian                     1\n",
       "          other                      1\n",
       "          pasta                      1\n",
       "6987      american                   2\n",
       "Length: 15435, dtype: int64"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "frame_test = historical_data[['store_id','store_primary_category']].groupby(by=['store_id','store_primary_category'],dropna=False).value_counts()\n",
    "frame_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "store_id_unique = historical_data[\"store_id\"].unique().tolist()\n",
    "store_id_and_category = {store_id: historical_data[historical_data.store_id == store_id].store_primary_category.mode() \n",
    "                         for store_id in store_id_unique}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fill(store_id):\n",
    "    \"\"\"Return primary store category from the dictionary\"\"\"\n",
    "    try:\n",
    "        return store_id_and_category[store_id].values[0]\n",
    "    except:\n",
    "        return np.nan\n",
    "\n",
    "# fill null values\n",
    "historical_data[\"clean_store_primary_category\"] = historical_data.store_id.apply(fill)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "## note that the number of non-null store_id values is less than the number of non-null \n",
    "# store_primary category values. We can probably fill in most of the missing values via inference\n",
    "\n",
    "## there are also stores with multiple store_primary_category values. Such stores might be 'ghost kitchens',\n",
    "# and need to be backfilled appropriately\n",
    "# TODO #1 write function to downfill NaN store_primary_category values\n",
    "\n",
    "def fillNulls_store_category(historical_data:pd.DataFrame) -> pd.DataFrame:\n",
    "    store_id_list = historical_data['store_id'].unique().tolist()\n",
    "    store_id_cat = {store_id: historical_data[historical_data.store_id == store_id].store_primary_category.mode() for store_id in store_id_list}\n",
    "    historical_data['clean_store_primary_category']\n",
    "    try:\n",
    "        for x in store_id_list:\n",
    "            historical_data['clean_store_primary_category'] = historical_data.store_id.apply(store_id_cat.values[0])\n",
    "    except Exception as ee:\n",
    "        raise ee\n",
    "    return historical_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "## update types\n",
    "## create target variable\n",
    "def addFeatures_durations(historical_data:pd.DataFrame) -> pd.DataFrame:\n",
    "    try:\n",
    "        historical_data['created_at'] = pd.to_datetime(historical_data['created_at'])\n",
    "        historical_data['actual_delivery_time'] = pd.to_datetime(historical_data['actual_delivery_time'])\n",
    "        ## calculate delivery duration\n",
    "        historical_data['actual_total_delivery_duration'] = (historical_data['actual_delivery_time'] - historical_data['created_at']).dt.total_seconds()\n",
    "        ## estimated time spent outside the store/not on order preparation\n",
    "        historical_data['est_time_non-prep'] = historical_data['estimated_order_place_duration'] + historical_data['estimated_store_to_consumer_driving_duration']\n",
    "        ## estimated time spent in the store/not driving\n",
    "        historical_data['est_time_prep'] = historical_data['actual_total_delivery_duration'] - historical_data['est_time_non-prep']\n",
    "    except Exception as ex:\n",
    "        raise ex\n",
    "    return historical_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "## add ratio features\n",
    "def addFeatures_ratios(historical_data:pd.DataFrame) -> pd.DataFrame:\n",
    "    try:\n",
    "        historical_data['busy_to_onshift'] = historical_data['total_busy_dashers'] / historical_data['total_onshift_dashers']\n",
    "        # drop infinite values\n",
    "        historical_data['busy_to_onshift'].replace([np.inf,-np.inf],np.nan,inplace=True)\n",
    "    except Exception as ex:\n",
    "        raise ex\n",
    "    return historical_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "## add dummies for categories\n",
    "def addFeatures_dummies(historical_data:pd.DataFrame,dummy_column:str) -> pd.DataFrame:\n",
    "    try:\n",
    "        dumm = pd.get_dummies(historical_data[dummy_column],prefix=str(dummy_column + '_'),dtype=float)\n",
    "        # concat dummies\n",
    "        historical_data = pd.concat([historical_data,dumm],axis=1)\n",
    "        historical_data = historical_data.drop(columns=[dummy_column])\n",
    "    except Exception as ex:\n",
    "        raise ex\n",
    "    return historical_data"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.7 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "96d1af5f869624c072d9e03e4f7fcffed44526ca720f1a36a76cd678c41e0e80"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
